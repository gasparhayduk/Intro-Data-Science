for (p in umbrales) {
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data)[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p), f1_score=metricas[1], precision=metricas[2], recall=metricas[3])
}
View(umbral_metricas)
umbral_metricas <- data.frame()
umbrales <- seq(0.001, 0.999, 0.001)
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data)[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
View(umbral_metricas)
row_max_f1 <- which.max(umbral_metricas$f1_score)
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[max_f1, "umbral"]
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"]
print(umbral_maxf1)
prec_maxf1 <- umbral_metricas[max_f1, "prec"]
prec_maxf1 <- umbral_metricas[row_max_f1, "prec"]
prec_maxf1 <- umbral_metricas[row_max_f1, "precision"]
recall_maxf1 <- umbral_metricas[row_max_f1, "recall"]
full_index <- c(val_index,train_index)
full_data <- churn_data[full_index,]
posta_full <- ifelse(full_data$Exited=="churn",1,0)
tree_fit_full <- rpart(Exited ~ ., data = full_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_test <- predict(tree_fit_full, newdata = test_data)[, "churn"]
auc_test_full <- get_auc(as.numeric(full_data$Exited == "churn", tree_predictions_test)
auc_test_full <- get_auc(as.numeric(full_data$Exited == "churn"), tree_predictions_test)
full_index <- c(val_index,train_index)
full_data <- churn_data[full_index,]
posta_full <- ifelse(full_data$Exited=="churn",1,0)
tree_fit_full <- rpart(Exited ~ ., data = full_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_test <- predict(tree_fit_full, newdata = test_data)[, "churn"]
auc_test_full <- get_auc(as.numeric(full_data$Exited == "churn"), tree_predictions_test)
View(full_data)
auc_test_full <- get_auc(as.numeric(test_data$Exited == "churn"), tree_predictions_test)
rpart.plot(tree_fit_full)
tree_fit_full$variable.importance
umbrales <- seq(0.001, 0.999, 0.001)
umbral_metricas <- matrix(nrow=999, ncol=4)
colnames(umbral_metricas) <- c("umbral", "f1_score", "prec", "recall")
umbral_metricas <- as.data.frame(umbral_metricas)
w=1
for (p in umbrales) {
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data)[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose=TRUE)
umbral_metricas[w,1] <- p
umbral_metricas[w,2] <- metricas[1]
umbral_metricas[w,3] <- metricas[2]
umbral_metricas[w,4] <- metricas[3]
w <- w+1
}
row_max_f1 <- which.max(umbral_metricas$f1_score)
print(umbral_metricas[row_max_f1,])
rm(list=ls())
setwd("~/Desktop/IntroDS/Taller03")
library(ROCR) # activamos la libreria.
library(rpart)
library(rpart.plot)
load_data <- function(data_path) {
# data_path: debe ser el path en donde se encuentra el archivo de datos
train_data <- read.table(data_path, sep=",", header=TRUE, quote="")
train_data$Exited <- factor(ifelse(train_data$Exited == 1, "churn", "no_churn"))
train_data$RowNumber <- NULL
train_data$Surname <- NULL
return(train_data)
}
get_auc <- function(real_class, predicted_prob) {
# real_class: debe ser un vector de 0 y 1, en donde 1 es la clase de interés
# predicted_prob: debe ser un vector de probabilidades predichas para la clase de interés
pred_ROCR <- prediction(predicted_prob, real_class)
auc_ROCR <- performance(pred_ROCR, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
return(auc_ROCR)
}
churn_data <- load_data("Churn_Modelling.csv")
val_index <- sample(c(1:nrow(churn_data)), 1100)
val_data <- churn_data[val_index,]
# 3) Cree un test-set con 1100 observaciones elegidas al azar (que
# no deben haber sido elegidas en el punto 2 como parte del conjunto
# del validation set).
test_index <- sample(setdiff(c(1:nrow(churn_data)), val_index), 1100)
test_data <- churn_data[test_index,]
# 4) Cree un training-set que sea igual a churn_data pero no incluya
# las observaciones extraídas tanto para el validation set como para
# el test set.
train_index <- setdiff(1:nrow(churn_data), c(val_index, test_index))
train_data <- churn_data[train_index,]
split_vals <- seq(1,10,1)
bucket_vals <- seq(1,10,1)
depth_vals <- seq(1,10,1)
rpart_exp <- data.frame()
for (s in split_vals) {
for (b in bucket_vals) {
for (d in depth_vals) {
print(c(s,b,d))
tree_fit <- rpart(Exited ~ ., data = train_data,
control = rpart.control(minsplit = s , minbucket = b , maxdepth = d , xval=0, cp = 0)) #entrenamos el arbol
tree_predictions_val <- predict(tree_fit, newdata = val_data, type="prob")[, "churn"] #prediccion para los datos de validación. Es un vector con la probabilidad de ser churn.
tree_predictions_train <- predict(tree_fit, newdata = train_data, type="prob")[, "churn"] #prediccion para los datos de training. Es un vector con la probabilidad de ser churn.
rpart_exp <- rbind(rpart_exp, data.frame(minsplit = s, minbucket = b, maxdepth = d,
auc_vd = get_auc(as.numeric(val_data$Exited == "churn"),
tree_predictions_val), auc_tr = get_auc(as.numeric(train_data$Exited == "churn"), tree_predictions_train)))
}
}
}
best_vd <- c() #el primer elemento hará referencia al minsplit, el segundo al minbucket y el tercero al maxdepth.
row_vd <- which.max(rpart_exp$auc_vd) #fila en la que se obtiene el maxor AUC en validación
print(rpart_exp[row_vd,])
w=1
while (w<=3){
best_vd[w] <- rpart_exp[row_vd,w]
w <- w+1
}
prec_recall <- function(conf_m, verbose=TRUE) {
if (verbose) {
print(conf_m)
}
prec <- conf_m["churn", "churn"] / sum((conf_m[, "churn"]))
rec <- conf_m["churn", "churn"] / sum((conf_m["churn",]))
f1 <- 2 * prec * rec / (prec + rec)
return(c(f1,prec,rec)) #devuelve un vector donde el primer elemento es el f1-score, el segundo elemento es la precision y el tercer elemento es el recall.
}
umbrales <- seq(0.001, 0.999, 0.001)
umbral_metricas <- data.frame()
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data)[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
# 8) Qué valores de precisión y recall arroja el modelo identificado en el punto
# anterior? (si fue más de un umbral el que maximiza F1 en el puntos anterior,
# elija el menor de los umbrales que encontró como solución de dicho punto).
prec_maxf1 <- umbral_metricas[row_max_f1, "precision"] #precision asociado al umbral que maximiza el f1-score
recall_maxf1 <- umbral_metricas[row_max_f1, "recall"]
full_index <- c(val_index,train_index)
full_data <- churn_data[full_index,]
tree_fit_full <- rpart(Exited ~ ., data = full_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_test <- predict(tree_fit_full, newdata = test_data)[, "churn"]
auc_test_full <- get_auc(as.numeric(test_data$Exited == "churn"), tree_predictions_test)
tree_fit_full$variable.importance
rpart.plot(tree_fit_full)
umbral_metricas <- matrix(nrow=999, ncol=4)
colnames(umbral_metricas) <- c("umbral", "f1_score", "prec", "recall")
umbral_metricas <- as.data.frame(umbral_metricas)
w=1
for (p in umbrales) {
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data)[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose=TRUE)
umbral_metricas[w,1] <- p
umbral_metricas[w,2] <- metricas[1]
umbral_metricas[w,3] <- metricas[2]
umbral_metricas[w,4] <- metricas[3]
w <- w+1
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
umbral_metricas <- data.frame()
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0)) #entrenamos el arbol con los mejores hiperparametros del ejercicio 5
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data, type = "prob")[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
metricas
rm(list=ls())
setwd("~/Desktop/IntroDS/Taller03")
library(ROCR) # activamos la libreria.
library(rpart)
library(rpart.plot)
load_data <- function(data_path) {
# data_path: debe ser el path en donde se encuentra el archivo de datos
train_data <- read.table(data_path, sep=",", header=TRUE, quote="")
train_data$Exited <- factor(ifelse(train_data$Exited == 1, "churn", "no_churn"))
train_data$RowNumber <- NULL
train_data$Surname <- NULL
return(train_data)
}
get_auc <- function(real_class, predicted_prob) {
# real_class: debe ser un vector de 0 y 1, en donde 1 es la clase de interés
# predicted_prob: debe ser un vector de probabilidades predichas para la clase de interés
pred_ROCR <- prediction(predicted_prob, real_class)
auc_ROCR <- performance(pred_ROCR, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
return(auc_ROCR)
}
# Se cargan los datos
churn_data <- load_data("Churn_Modelling.csv")
folds <- 10
kfoldcv_acc <- rep(NA, folds)
fold_indicator <- sample(rep_len((1:folds), nrow(churn_data)))
for (f in c(1:folds)) {
training_data <- churn_data[fold_indicator!=f,]
valid_data  <- churn_data[fold_indicator==f,]
tree_fit <- rpart(Exited ~ ., data = training_data)
tree_predictions <- predict(tree_fit, newdata = valid_data, type = "class")
kfoldcv_acc[f]  <- mean(valid_data$Exited == tree_predictions)
}
mean(kfoldcv_acc) #nos da una media igual a 0.8584.
kfold_media <- mean(kfoldcv_acc)
val_index <- sample(c(1:nrow(churn_data)), 1100)
val_data <- churn_data[val_index,]
# 3) Cree un test-set con 1100 observaciones elegidas al azar (que
# no deben haber sido elegidas en el punto 2 como parte del conjunto
# del validation set).
test_index <- sample(setdiff(c(1:nrow(churn_data)), val_index), 1100)
test_data <- churn_data[test_index,]
# 4) Cree un training-set que sea igual a churn_data pero no incluya
# las observaciones extraídas tanto para el validation set como para
# el test set.
train_index <- setdiff(1:nrow(churn_data), c(val_index, test_index))
train_data <- churn_data[train_index,]
split_vals <- seq(1,10,1)
bucket_vals <- seq(1,10,1)
depth_vals <- seq(1,10,1)
# Dataset para ir completando la informacion de cada combinacion de minsplit, minbucket y maxdepth:
rpart_exp <- data.frame()
for (s in split_vals) {
for (b in bucket_vals) {
for (d in depth_vals) {
print(c(s,b,d))
tree_fit <- rpart(Exited ~ ., data = train_data,
control = rpart.control(minsplit = s , minbucket = b , maxdepth = d , xval=0, cp = 0)) #entrenamos el arbol
tree_predictions_val <- predict(tree_fit, newdata = val_data, type="prob")[, "churn"] #prediccion para los datos de validación. Es un vector con la probabilidad de ser churn.
tree_predictions_train <- predict(tree_fit, newdata = train_data, type="prob")[, "churn"] #prediccion para los datos de training. Es un vector con la probabilidad de ser churn.
rpart_exp <- rbind(rpart_exp, data.frame(minsplit = s, minbucket = b, maxdepth = d,
auc_vd = get_auc(as.numeric(val_data$Exited == "churn"),
tree_predictions_val), auc_tr = get_auc(as.numeric(train_data$Exited == "churn"), tree_predictions_train)))
}
}
}
best_vd <- c() #el primer elemento hará referencia al minsplit, el segundo al minbucket y el tercero al maxdepth.
row_vd <- which.max(rpart_exp$auc_vd) #fila en la que se obtiene el maxor AUC en validación
print(rpart_exp[row_vd,])
w=1
while (w<=3){
best_vd[w] <- rpart_exp[row_vd,w]
w <- w+1
}
prec_recall <- function(conf_m, verbose=TRUE) {
if (verbose) {
print(conf_m)
}
prec <- conf_m["churn", "churn"] / sum((conf_m[, "churn"]))
rec <- conf_m["churn", "churn"] / sum((conf_m["churn",]))
f1 <- 2 * prec * rec / (prec + rec)
return(c(f1,prec,rec)) #devuelve un vector donde el primer elemento es el f1-score, el segundo elemento es la precision y el tercer elemento es el recall.
}
umbrales <- seq(0.001, 0.999, 0.001)
umbral_metricas <- data.frame()
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0)) #entrenamos el arbol con los mejores hiperparametros del ejercicio 5
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data, type = "prob")[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
umbrales <- seq(0.001, 0.999, 0.001)
# Definimos el dataframe donde completaremos cuál es el f1-score, precision y recall para cada umbral.
umbral_metricas <- data.frame()
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0)) #entrenamos el arbol con los mejores hiperparametros del ejercicio 5
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data, type = "prob")[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
prec_maxf1 <- umbral_metricas[row_max_f1, "precision"] #precision asociado al umbral que maximiza el f1-score
recall_maxf1 <- umbral_metricas[row_max_f1, "recall"]
full_index <- c(val_index,train_index)
full_data <- churn_data[full_index,]
tree_fit_full <- rpart(Exited ~ ., data = full_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_test <- predict(tree_fit_full, newdata = test_data, type="prob")[, "churn"]
auc_test_full <- get_auc(as.numeric(test_data$Exited == "churn"), tree_predictions_test)
tree_fit_full$variable.importance
rpart.plot(tree_fit_full)
rm(list=ls())
setwd("~/Desktop/IntroDS/Taller03") # seteamos el directorio de trabajo
#Instalacion/activacion de librerias:
install.packages("ROCR") # instalamos la libreria (no estaba instalada en mi caso)
library(ROCR) # activamos la libreria.
library(rpart)
library(rpart.plot)
install.packages("ROCR")
rm(list=ls())
setwd("~/Desktop/IntroDS/Taller03")
library(ROCR) # activamos la libreria.
library(rpart)
library(rpart.plot)
load_data <- function(data_path) {
# data_path: debe ser el path en donde se encuentra el archivo de datos
train_data <- read.table(data_path, sep=",", header=TRUE, quote="")
train_data$Exited <- factor(ifelse(train_data$Exited == 1, "churn", "no_churn"))
train_data$RowNumber <- NULL
train_data$Surname <- NULL
return(train_data)
}
get_auc <- function(real_class, predicted_prob) {
# real_class: debe ser un vector de 0 y 1, en donde 1 es la clase de interés
# predicted_prob: debe ser un vector de probabilidades predichas para la clase de interés
pred_ROCR <- prediction(predicted_prob, real_class)
auc_ROCR <- performance(pred_ROCR, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
return(auc_ROCR)
}
churn_data <- load_data("Churn_Modelling.csv")
folds <- 10
kfoldcv_acc <- rep(NA, folds)
fold_indicator <- sample(rep_len((1:folds), nrow(churn_data)))
for (f in c(1:folds)) {
training_data <- churn_data[fold_indicator!=f,]
valid_data  <- churn_data[fold_indicator==f,]
tree_fit <- rpart(Exited ~ ., data = training_data)
tree_predictions <- predict(tree_fit, newdata = valid_data, type = "class")
kfoldcv_acc[f]  <- mean(valid_data$Exited == tree_predictions)
}
kfold_media <- mean(kfoldcv_acc) #nos da una media igual a 0.8584.
val_index <- sample(c(1:nrow(churn_data)), 1100)
val_data <- churn_data[val_index,]
# 3) Cree un test-set con 1100 observaciones elegidas al azar (que
# no deben haber sido elegidas en el punto 2 como parte del conjunto
# del validation set).
test_index <- sample(setdiff(c(1:nrow(churn_data)), val_index), 1100)
test_data <- churn_data[test_index,]
# 4) Cree un training-set que sea igual a churn_data pero no incluya
# las observaciones extraídas tanto para el validation set como para
# el test set.
train_index <- setdiff(1:nrow(churn_data), c(val_index, test_index))
train_data <- churn_data[train_index,]
split_vals <- seq(1,10,1)
bucket_vals <- seq(1,10,1)
depth_vals <- seq(1,10,1)
# Dataset para ir completando la informacion de cada combinacion de minsplit, minbucket y maxdepth:
rpart_exp <- data.frame()
for (s in split_vals) {
for (b in bucket_vals) {
for (d in depth_vals) {
print(c(s,b,d))
tree_fit <- rpart(Exited ~ ., data = train_data,
control = rpart.control(minsplit = s , minbucket = b , maxdepth = d , xval=0, cp = 0)) #entrenamos el arbol
tree_predictions_val <- predict(tree_fit, newdata = val_data, type="prob")[, "churn"] #prediccion para los datos de validación. Es un vector con la probabilidad de ser churn.
tree_predictions_train <- predict(tree_fit, newdata = train_data, type="prob")[, "churn"] #prediccion para los datos de training. Es un vector con la probabilidad de ser churn.
rpart_exp <- rbind(rpart_exp, data.frame(minsplit = s, minbucket = b, maxdepth = d,
auc_vd = get_auc(as.numeric(val_data$Exited == "churn"),
tree_predictions_val), auc_tr = get_auc(as.numeric(train_data$Exited == "churn"), tree_predictions_train)))
}
}
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
rm(list=ls())
setwd("~/Desktop/IntroDS/Taller03")
library(ROCR) # activamos la libreria.
library(rpart)
library(rpart.plot)
load_data <- function(data_path) {
# data_path: debe ser el path en donde se encuentra el archivo de datos
train_data <- read.table(data_path, sep=",", header=TRUE, quote="")
train_data$Exited <- factor(ifelse(train_data$Exited == 1, "churn", "no_churn"))
train_data$RowNumber <- NULL
train_data$Surname <- NULL
return(train_data)
}
get_auc <- function(real_class, predicted_prob) {
# real_class: debe ser un vector de 0 y 1, en donde 1 es la clase de interés
# predicted_prob: debe ser un vector de probabilidades predichas para la clase de interés
pred_ROCR <- prediction(predicted_prob, real_class)
auc_ROCR <- performance(pred_ROCR, measure = "auc")
auc_ROCR <- auc_ROCR@y.values[[1]]
return(auc_ROCR)
}
# Se cargan los datos
churn_data <- load_data("Churn_Modelling.csv")
folds <- 10
kfoldcv_acc <- rep(NA, folds)
fold_indicator <- sample(rep_len((1:folds), nrow(churn_data)))
for (f in c(1:folds)) {
training_data <- churn_data[fold_indicator!=f,]
valid_data  <- churn_data[fold_indicator==f,]
tree_fit <- rpart(Exited ~ ., data = training_data)
tree_predictions <- predict(tree_fit, newdata = valid_data, type = "class")
kfoldcv_acc[f]  <- mean(valid_data$Exited == tree_predictions)
}
kfold_media <- mean(kfoldcv_acc) #nos da una media igual a 0.8584.
val_index <- sample(c(1:nrow(churn_data)), 1100)
val_data <- churn_data[val_index,]
# 3) Cree un test-set con 1100 observaciones elegidas al azar (que
# no deben haber sido elegidas en el punto 2 como parte del conjunto
# del validation set).
test_index <- sample(setdiff(c(1:nrow(churn_data)), val_index), 1100)
test_data <- churn_data[test_index,]
# 4) Cree un training-set que sea igual a churn_data pero no incluya
# las observaciones extraídas tanto para el validation set como para
# el test set.
train_index <- setdiff(1:nrow(churn_data), c(val_index, test_index))
train_data <- churn_data[train_index,]
split_vals <- seq(1,10,1)
bucket_vals <- seq(1,10,1)
depth_vals <- seq(1,10,1)
rpart_exp <- data.frame()
for (s in split_vals) {
for (b in bucket_vals) {
for (d in depth_vals) {
print(c(s,b,d))
tree_fit_exp <- rpart(Exited ~ ., data = train_data,
control = rpart.control(minsplit = s , minbucket = b , maxdepth = d , xval=0, cp = 0)) #entrenamos el arbol
tree_predictions_val <- predict(tree_fit_exp, newdata = val_data, type="prob")[, "churn"] #prediccion para los datos de validación. Es un vector con la probabilidad de ser churn.
tree_predictions_train <- predict(tree_fit_exp, newdata = train_data, type="prob")[, "churn"] #prediccion para los datos de training. Es un vector con la probabilidad de ser churn.
rpart_exp <- rbind(rpart_exp, data.frame(minsplit = s, minbucket = b, maxdepth = d,
auc_vd = get_auc(as.numeric(val_data$Exited == "churn"),
tree_predictions_val), auc_tr = get_auc(as.numeric(train_data$Exited == "churn"), tree_predictions_train)))
}
}
}
best_vd <- c() #el primer elemento hará referencia al minsplit, el segundo al minbucket y el tercero al maxdepth.
row_vd <- which.max(rpart_exp$auc_vd) #fila en la que se obtiene el maxor AUC en validación
print(rpart_exp[row_vd,])
w=1
while (w<=3){
best_vd[w] <- rpart_exp[row_vd,w]
w <- w+1
}
prec_recall <- function(conf_m, verbose=TRUE) {
if (verbose) {
print(conf_m)
}
prec <- conf_m["churn", "churn"] / sum((conf_m[, "churn"]))
rec <- conf_m["churn", "churn"] / sum((conf_m["churn",]))
f1 <- 2 * prec * rec / (prec + rec)
return(c(f1,prec,rec)) #devuelve un vector donde el primer elemento es el f1-score, el segundo elemento es la precision y el tercer elemento es el recall.
}
umbrales <- seq(0.001, 0.999, 0.001)
# Definimos el dataframe donde completaremos cuál es el f1-score, precision y recall para cada umbral.
umbral_metricas <- data.frame()
# Loop para probar con todos los umbrales
for (p in umbrales) {
print(p)
tree_fit_f1 <- rpart(Exited ~ ., data = val_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0)) #entrenamos el arbol con los mejores hiperparametros del ejercicio 5
tree_predictions_val_f1 <- predict(tree_fit_f1, newdata = val_data, type = "prob")[, "churn"]
conf_m_ <- table(actual=val_data$Exited, pred=factor(ifelse(tree_predictions_val_f1>=p, "churn", "no_churn"))) #matriz de confusion para calcular el f1-score
metricas <- prec_recall(conf_m_,verbose = TRUE)
umbral_metricas <- rbind(umbral_metricas, data.frame(umbral=p, f1_score=metricas[1], precision=metricas[2], recall=metricas[3]))
}
row_max_f1 <- which.max(umbral_metricas$f1_score) #obtenemos la fila en la que ocurre el mayor f1-score
print(umbral_metricas[row_max_f1,])
umbral_maxf1 <- umbral_metricas[row_max_f1, "umbral"] #umbral que maximiza el f1-score. El umbral es de 0.33 (raro que sea bajo)
print(umbral_maxf1)
prec_maxf1 <- umbral_metricas[row_max_f1, "precision"] #precision asociado al umbral que maximiza el f1-score
recall_maxf1 <- umbral_metricas[row_max_f1, "recall"] #recall asociado al umbral que maximiza el f1-score
#la precision asociada al umbral que maximiza el f1-score es 0.76,
# mientras que la recall asociada al umbral que maximiza el f1-score es 0.75
full_index <- c(val_index,train_index)
full_data <- churn_data[full_index,]
tree_fit_full <- rpart(Exited ~ ., data = full_data,
control = rpart.control(minsplit = best_vd[1] , minbucket = best_vd[2] , maxdepth = best_vd[3] , xval=0, cp = 0))
tree_predictions_test <- predict(tree_fit_full, newdata = test_data, type="prob")[, "churn"]
auc_test_full <- get_auc(as.numeric(test_data$Exited == "churn"), tree_predictions_test)
tree_fit_full$variable.importance
rpart.plot(tree_fit_full)
